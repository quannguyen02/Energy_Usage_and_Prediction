{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2fa338-376a-48fb-9729-4262a66ed180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model: https://machinelearningmastery.com/how-to-develop-lstm-models-for-time-series-forecasting/\n",
    "# model: https://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/\n",
    "# predict ahead: https://towardsdatascience.com/time-series-forecasting-with-recurrent-neural-networks-74674e289816"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "607d3a9e-2503-4187-8345-3101f66219af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import os, math\n",
    "import preprocess\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import RepeatVector\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "from tensorflow.keras.layers import Masking\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "f4fbec1d-6aa0-44ac-ac59-fa59639d5aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3661, 12) (3631, 30, 12) (3631, 1, 12)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"Data/Electrical_Averaged.csv\")\n",
    "data[\"Timestamp\"] = pd.to_datetime(data['Timestamp'])\n",
    "data.set_index('Timestamp', inplace=True)\n",
    "building_data = preprocess.remove_outliers(data, 15)\n",
    "\n",
    "# normalize the dataset\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(building_data)\n",
    "\n",
    "n_steps_in = 30\n",
    "n_steps_out = 1\n",
    "mask_value = 0\n",
    "tf.random.set_seed(1)\n",
    "\n",
    "# set check point\n",
    "checkpoint_path = f\"training_1/checkpoint__{n_steps_in}in_{n_steps_out}_out\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "def generate_sequence(data, n_steps_in, n_steps_out):\n",
    "    X, y = list(), list()\n",
    "    for index in range(n_steps_in, len(data)-n_steps_out+1):\n",
    "        X.append(data[index-n_steps_in : index])\n",
    "        y.append(data[index : index+n_steps_out])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "scaled_data[np.isnan(scaled_data)] = mask_value\n",
    "X, y = generate_sequence(scaled_data, n_steps_in, n_steps_out)\n",
    "\n",
    "n_features = X.shape[2]\n",
    "print(scaled_data.shape, X.shape, y.shape)\n",
    "\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Masking(mask_value= mask_value, input_shape=(n_steps_in, n_features)))\n",
    "model.add(LSTM(200, activation='relu'))\n",
    "model.add(RepeatVector(n_steps_out))\n",
    "model.add(LSTM(200, activation='relu', return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(n_features)))\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "cc4e5ec9-9c62-42ef-ba3d-5b7d4019657e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restore the weights\n",
    "model.load_weights(f'./Weight/weight_{n_steps_in}in_{n_steps_out}_out')\n",
    "\n",
    "ahead = 365\n",
    "\n",
    "def predict_ahead(X, model, n_ahead):\n",
    "    yhat = list()\n",
    "    X_copy = np.copy(X)\n",
    "    for _ in range(n_ahead):\n",
    "        prediction = model.predict(X_copy, verbose=0)\n",
    "        yhat.append(prediction[0, 0])\n",
    "        X_copy = np.concatenate((X_copy, prediction), axis=1)[:,1:]\n",
    "    return np.array(yhat)\n",
    "yhat = predict_ahead(X[-1:], model, ahead)    \n",
    "yhat = scaler.inverse_transform(yhat)\n",
    "time_period = pd.date_range(building_data.index[-1], periods=ahead+1, freq=\"d\")[1:]\n",
    "yhat = pd.DataFrame(yhat, columns = building_data.columns, index = time_period)\n",
    "yhat.index.name = \"Timestamp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "cf3329b8-26f9-444e-89a8-97a3e786e627",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat.index.name = \"Timestamp\"\n",
    "yhat.to_csv(\"Data/Electrical_Predict.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "fa84c4ef-8aa4-44e3-b264-3034c22af065",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "7099993b-51ce-45f0-8622-db2557da3565",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = pd.DataFrame(yhat, columns = building_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0c228a-1023-4c89-b2f7-29cbf6e01491",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.append(data_to_append, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1682969-87de-4d3c-bb43-c35d7fafa9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model\n",
    "model.fit(X, y, epochs=200, verbose=0, callbacks=[cp_callback])\n",
    "# Save the weights\n",
    "model.save_weights(f'./Weight/weight_{n_steps_in}in_{n_steps_out}_out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1378b5-f25c-46ff-aefb-44284d1cfa75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model\n",
    "model.fit(X, y, epochs=200, verbose=0, callbacks=[cp_callback])\n",
    "# Save the weights\n",
    "model.save_weights(f'./Weight/weight_{n_steps_in}in_{n_steps_out}_out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8406aaf-660f-449e-b73a-a4aa3891214c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408076bb-0b44-4009-9df2-b14c2a3d5cfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9910b355-1489-43f3-983f-6f28fec7a482",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d8f6c0-4906-49bb-9fa7-9c76766e3bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # split a multivariate sequence into samples\n",
    "# def split_sequences(sequences, n_steps_in, n_steps_out):\n",
    "#     X, y = list(), list()\n",
    "#     for i in range(len(sequences)):\n",
    "#         # find the end of this pattern\n",
    "#         end_ix = i + n_steps_in\n",
    "#         out_end_ix = end_ix + n_steps_out\n",
    "#         # check if we are beyond the dataset\n",
    "#         if out_end_ix > len(sequences):\n",
    "#             break\n",
    "#         # gather input and output parts of the pattern\n",
    "#         seq_x, seq_y = sequences[i:end_ix, :], sequences[end_ix:out_end_ix, :]\n",
    "#         X.append(seq_x)\n",
    "#         y.append(seq_y)\n",
    "#     return array(X), array(y)\n",
    " \n",
    "# # define input sequence\n",
    "# in_seq1 = array([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
    "# in_seq2 = array([15, 25, 35, 45, 55, 65, 75, 85, 95])\n",
    "# out_seq = array([in_seq1[i]+in_seq2[i] for i in range(len(in_seq1))])\n",
    "# # convert to [rows, columns] structure\n",
    "# in_seq1 = in_seq1.reshape((len(in_seq1), 1))\n",
    "# in_seq2 = in_seq2.reshape((len(in_seq2), 1))\n",
    "# out_seq = out_seq.reshape((len(out_seq), 1))\n",
    "# # horizontally stack columns\n",
    "# dataset = hstack((in_seq1, in_seq2, out_seq))\n",
    "# # choose a number of time steps\n",
    "# n_steps_in, n_steps_out = 3, 2\n",
    "# # covert into input/output\n",
    "# X, y = split_sequences(dataset, n_steps_in, n_steps_out)\n",
    "# # the dataset knows the number of features, e.g. 2\n",
    "# n_features = X.shape[2]\n",
    "# print(X.shape, y.shape)\n",
    "# # summarize the data\n",
    "# for i in range(len(X)):\n",
    "#     print(X[i], y[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
